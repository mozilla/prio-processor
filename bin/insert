#!/bin/bash
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at https://mozilla.org/MPL/2.0/.

# Script to map aggregates to origins and insert the results into BigQuery. Note
# that this script expects direct access to a GCS bucket for processing instead
# of using a MinIO gateway.

set -euo pipefail
set -x

today=$(python3 -c "from datetime import datetime as dt; print(dt.utcnow().isoformat()[:10])")
: "${APP_NAME?}"
: "${SUBMISSION_DATE:=${today}}"
: "${BUCKET_PREFIX:=data/v1}"
# assumes that data is stored according to convention set in process
: "${BUCKET_INTERNAL_PRIVATE?}"
: "${PUBLIC_KEY_HEX_EXTERNAL?}"
: "${DATA_CONFIG?}"
: "${ORIGIN_CONFIG?}"
: "${GOOGLE_APPLICATION_CREDENTIALS?:=}"

: "${DATASET:-telemetry}"
: "${TABLE:-content_blocking_dev}"

# set to "true" to overwrite the existing table
: "${BQ_REPLACE:-false}"

function index() {
    # Map the resulting aggregates against the list of origins.

    local input=$1
    local output=$2

    resources=$(mktemp -d -t resources-XXX)
    source "${BASH_SOURCE%/*}/dataproc"
    SUBMODULE="origin" bootstrap "${resources}"

    spark-submit \
        --py-files "${resources}/prio_processor.egg" \
        "${resources}/processor-origin.py" \
        index \
        --input "${input}" \
        --output "${output}" \
        --config "${DATA_CONFIG}" \
        --origins "${ORIGIN_CONFIG}"
}

function insert() {
    # Insert processed data into a BigQuery table in the current project.

    local input=$1
    local dataset=$2
    local table=$3

    if ! bq ls | grep "${dataset}" > /dev/null ; then
        echo "creating dataset: ${dataset}"
        bq mk "${dataset}"
    fi

    bq load \
        --source_format=NEWLINE_DELIMITED_JSON \
        --autodetect \
        --replace="${BQ_REPLACE}" \
        "${dataset}.${table}" \
        "${input}"

    bq query "select count(*) from ${dataset}.${table}"
}

function main() {
    data_in=$(mktemp -d -t data-XXX)
    data_out=$(mktemp -d -t data-XXX)

    "${BASH_SOURCE%/*}/authenticate"

    prefix=${BUCKET_PREFIX}/${PUBLIC_KEY_HEX_EXTERNAL}/${APP_NAME}/${SUBMISSION_DATE}
    gsutil -m cp -r "gs://${BUCKET_INTERNAL_PRIVATE}/${prefix}/processed/publish" "${data_in}"
    index "${data_in}" "${data_out}"

    insert "${data_out}"/*.json "${DATASET}" "${TABLE}"
}

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
